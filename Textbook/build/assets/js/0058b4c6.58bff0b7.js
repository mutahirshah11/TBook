"use strict";(globalThis.webpackChunkbook=globalThis.webpackChunkbook||[]).push([[849],{6164:t=>{t.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Part 1: Foundations of Physical AI","items":[{"type":"link","href":"/docs/part1/foundations-physical-ai","label":"Chapter 1. Foundations of Physical AI & embodied intelligence ","docId":"part1/foundations-physical-ai","unlisted":false},{"type":"link","href":"/docs/part1/chapter2-embodied-ai","label":"Chpater 2 : Embodied AI and Physical Laws ","docId":"part1/chapter2-embodied-ai","unlisted":false},{"type":"link","href":"/docs/part1/chapter3-humanoid-landscape","label":"Chpater 3 : Overview on humanoid robotics landscape","docId":"part1/chapter3-humanoid-landscape","unlisted":false},{"type":"link","href":"/docs/part1/chapter4-sensor-systems","label":"Chapter 4: Sensor systems: LIDAR, cameras, IMUs, force/torque sensors","docId":"part1/chapter4-sensor-systems","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Part 2: Embodied AI & ROS 2 Foundations","items":[{"type":"link","href":"/docs/part2/chapter-5-ros2-architecture-and-core-concepts","label":"Chapter 5:ROS 2 Architecture","docId":"part2/chapter-5-ros2-architecture-and-core-concepts","unlisted":false},{"type":"link","href":"/docs/part2/chapter-6-nodes-topics-services-actions","label":"Chapter 6: Nodes, Topics, Services, and Actions","docId":"part2/chapter-6-nodes-topics-services-actions","unlisted":false},{"type":"link","href":"/docs/part2/chapter-7-building-packages","label":"Chapter 7: Building ROS 2 Packages with Python","docId":"part2/chapter-7-building-packages","unlisted":false},{"type":"link","href":"/docs/part2/chapter_8","label":"Chapter 8: Launch Files and Parameter Management","docId":"part2/chapter_8","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Part 3: Robot Simulation with Gazebo","items":[{"type":"link","href":"/docs/part3/chapter_9","label":"Chapter 9: Gazebo Simulation Environment Setup","docId":"part3/chapter_9","unlisted":false},{"type":"link","href":"/docs/part3/chapter_10","label":"Chapter 10: URDF and SDF Robot Description Formats","docId":"part3/chapter_10","unlisted":false},{"type":"link","href":"/docs/part3/chapter_11","label":"Chapter 11: Physics Simulation and Sensor Simulation","docId":"part3/chapter_11","unlisted":false},{"type":"link","href":"/docs/part3/chapter-12-unity-viz","label":"chapter-12-unity-viz","docId":"part3/chapter-12-unity-viz","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Part 4: NVIDIA Isaac Platform","items":[{"type":"link","href":"/docs/part4/chapter-13-isaac-intro","label":"Chapter 13: NVIDIA Isaac SDK and Isaac Sim","docId":"part4/chapter-13-isaac-intro","unlisted":false},{"type":"link","href":"/docs/part4/chapter-14-perception","label":"Chapter 14: AI-powered perception and manipulation","docId":"part4/chapter-14-perception","unlisted":false},{"type":"link","href":"/docs/part4/chapter-15-rl-control","label":"Chapter 15: Reinforcement learning for robot control","docId":"part4/chapter-15-rl-control","unlisted":false},{"type":"link","href":"/docs/part4/chapter-16-sim-to-real","label":"Chapter 16: Sim-to-real transfer techniques","docId":"part4/chapter-16-sim-to-real","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Part 5: Humanoid Robot Development","items":[{"type":"link","href":"/docs/part5/chapter-17-kinematics-dynamics","label":"Chapter 17: Kinematics & Dynamics","docId":"part5/chapter-17-kinematics-dynamics","unlisted":false},{"type":"link","href":"/docs/part5/chapter-18-locomotion","label":"Chapter 18: Locomotion","docId":"part5/chapter-18-locomotion","unlisted":false},{"type":"link","href":"/docs/part5/chapter-19-manipulation","label":"Chapter 19: Manipulation","docId":"part5/chapter-19-manipulation","unlisted":false},{"type":"link","href":"/docs/part5/chapter-20-hri","label":"Chapter 20: HRI","docId":"part5/chapter-20-hri","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Part 6: Conversational Robotics","items":[{"type":"link","href":"/docs/part6/chapter-21-llm-integration","label":"Chapter 21: LLM Integration","docId":"part6/chapter-21-llm-integration","unlisted":false},{"type":"link","href":"/docs/part6/chapter-22-speech-nlu","label":"Chapter 22: Speech & NLU","docId":"part6/chapter-22-speech-nlu","unlisted":false},{"type":"link","href":"/docs/part6/chapter-23-multimodal","label":"Chapter 23: Multi-Modal","docId":"part6/chapter-23-multimodal","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"part1/chapter2-embodied-ai":{"id":"part1/chapter2-embodied-ai","title":" 2: Embodied AI and Physical Laws","description":"From digital brains to physical bodies: understanding constraints, dynamics, and energy.","sidebar":"tutorialSidebar"},"part1/chapter3-humanoid-landscape":{"id":"part1/chapter3-humanoid-landscape","title":"Chapter 3: The Humanoid Robotics Landscape","description":"An overview of humanoid robot types, history, and the current industry landscape, setting the stage for Physical AI.","sidebar":"tutorialSidebar"},"part1/chapter4-sensor-systems":{"id":"part1/chapter4-sensor-systems","title":"Chapter 4: Sensor Systems: The Perceptual Backbone","description":"An overview of LiDAR, Cameras, IMUs, and Force/Torque sensors\u2014the inputs that drive Physical AI.","sidebar":"tutorialSidebar"},"part1/foundations-physical-ai":{"id":"part1/foundations-physical-ai","title":"Chapter 1: Foundations of Physical AI","description":"An introduction to Physical AI, Embodied Intelligence, and the core components that distinguish robots from purely software-based agents.","sidebar":"tutorialSidebar"},"part2/chapter_8":{"id":"part2/chapter_8","title":"Chapter 8: Launch Files and Parameter Management","description":"Introduction","sidebar":"tutorialSidebar"},"part2/chapter-5-ros2-architecture-and-core-concepts":{"id":"part2/chapter-5-ros2-architecture-and-core-concepts","title":"ROS 2 Architecture and Core Concepts","description":"Understanding nodes, topics, services, actions, and the underlying middleware.","sidebar":"tutorialSidebar"},"part2/chapter-6-nodes-topics-services-actions":{"id":"part2/chapter-6-nodes-topics-services-actions","title":"Nodes, Topics, Services, and Actions","description":"This chapter explores the fundamental communication primitives in ROS 2. We\'ll cover Nodes, the ROS Graph, and the three main communication patterns: Topics (Publisher/Subscriber), Services (Client/Server), and Actions (Goal/Feedback/Result).","sidebar":"tutorialSidebar"},"part2/chapter-7-building-packages":{"id":"part2/chapter-7-building-packages","title":"Building ROS 2 Packages with Python","description":"In Chapter 6, we looked at individual nodes and communication patterns. Now, we\'ll learn how to organize that code into Packages, which are the standard unit of software distribution in ROS 2.","sidebar":"tutorialSidebar"},"part3/chapter_10":{"id":"part3/chapter_10","title":"Chapter 10: URDF and SDF Robot Description Formats","description":"Introduction","sidebar":"tutorialSidebar"},"part3/chapter_11":{"id":"part3/chapter_11","title":"Chapter 11: Physics Simulation and Sensor Simulation","description":"Introduction","sidebar":"tutorialSidebar"},"part3/chapter_9":{"id":"part3/chapter_9","title":"Chapter 9: Gazebo Simulation Environment Setup","description":"Introduction","sidebar":"tutorialSidebar"},"part3/chapter-12-unity-viz":{"id":"part3/chapter-12-unity-viz","title":"chapter-12-unity-viz","description":"Troubleshooting","sidebar":"tutorialSidebar"},"part4/chapter-13-isaac-intro":{"id":"part4/chapter-13-isaac-intro","title":"Chapter 13: Introduction to NVIDIA Isaac Platform","description":"Introduction","sidebar":"tutorialSidebar"},"part4/chapter-14-perception":{"id":"part4/chapter-14-perception","title":"Chapter 14: AI-Powered Perception and Manipulation","description":"Introduction","sidebar":"tutorialSidebar"},"part4/chapter-15-rl-control":{"id":"part4/chapter-15-rl-control","title":"Chapter 15: Reinforcement Learning for Robot Control","description":"Introduction","sidebar":"tutorialSidebar"},"part4/chapter-16-sim-to-real":{"id":"part4/chapter-16-sim-to-real","title":"Chapter 16: Sim-to-Real Transfer Techniques","description":"The Reality Gap","sidebar":"tutorialSidebar"},"part5/chapter-17-kinematics-dynamics":{"id":"part5/chapter-17-kinematics-dynamics","title":"Chapter 17: Humanoid Robot Kinematics and Dynamics","description":"Introduction","sidebar":"tutorialSidebar"},"part5/chapter-18-locomotion":{"id":"part5/chapter-18-locomotion","title":"Chapter 18: Bipedal Locomotion and Balance Control","description":"Introduction","sidebar":"tutorialSidebar"},"part5/chapter-19-manipulation":{"id":"part5/chapter-19-manipulation","title":"Chapter 19: Manipulation and Grasping with Humanoid Hands","description":"Introduction","sidebar":"tutorialSidebar"},"part5/chapter-20-hri":{"id":"part5/chapter-20-hri","title":"Chapter 20: Natural Human-Robot Interaction Design","description":"Introduction","sidebar":"tutorialSidebar"},"part6/chapter-21-llm-integration":{"id":"part6/chapter-21-llm-integration","title":"Chapter 21: Integrating GPT Models for Conversational AI","description":"Introduction","sidebar":"tutorialSidebar"},"part6/chapter-22-speech-nlu":{"id":"part6/chapter-22-speech-nlu","title":"Chapter 22: Speech Recognition and Natural Language Understanding","description":"Introduction","sidebar":"tutorialSidebar"},"part6/chapter-23-multimodal":{"id":"part6/chapter-23-multimodal","title":"Chapter 23: Multi-Modal Interaction","description":"Introduction","sidebar":"tutorialSidebar"}}}}')}}]);